{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Spam Classifier Attempt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Data prep\n",
    "# train_dir = '/home/datadrive/PythonDev/datasets/Spam/raw/easy_ham'\n",
    "# spam_train_dir = '/home/datadrive/PythonDev/datasets/Spam/raw/spam'\n",
    "# processed_dir = '/home/datadrive/PythonDev/datasets/Spam/Processed/'\n",
    "dataset_dir = '/home/datadrive/PythonDev/datasets/Spam/'\n",
    "spam_zip = os.path.join(dataset_dir, 'mail_zip/spam')    \n",
    "ham_zip = os.path.join(dataset_dir, 'mail_zip/ham')\n",
    "ham_unzip = os.path.join(dataset_dir, 'mail_unziped/ham')\n",
    "spam_unzip = os.path.join(dataset_dir, 'mail_unziped/spam')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def html_cleaner(text):\n",
    "    cleaned = re.sub(r\"(?s)[\\n]?\", \"\", text)\n",
    "    # Next remove the remaining tags:\n",
    "    cleaned = re.sub(r\"(?s)<.*?>\", \"\", cleaned)\n",
    "    # Finally deal with whitespace\n",
    "    cleaned = re.sub(r\" \", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"^$\", \" \", cleaned)\n",
    "    cleaned = re.sub(\"''|,\", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"  \", \" \", cleaned)\n",
    "    return cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**velocity** $= \\begin{pmatrix}\n",
    "10 \\\\\n",
    "50 \\\\\n",
    "5000 \\\\\n",
    "\\end{pmatrix}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to analyse emails to determine content type, subject line\n",
    "\n",
    "\n",
    "def read_subject(file, spam_ham):\n",
    "    all_words = []\n",
    "    subject = ''\n",
    "    content_type = ''\n",
    "    \n",
    "    with open(file) as m:\n",
    "        for i, line in enumerate(m):\n",
    "            if subject == '':\n",
    "                if line.rfind('Subject:',0) > -1:\n",
    "                    subject = line[9:]\n",
    "            if content_type == '':\n",
    "                if line.rfind('Content-Type:', 0) > -1:\n",
    "                    content_type = line[14:]\n",
    "        return [file, spam_ham, subject, content_type]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def unzip_dir(path, extract_path):\n",
    "    cnt = 0\n",
    "    for zip in os.listdir(path):\n",
    "        file_path = os.path.join(path, zip)\n",
    "        print('Unziping ', file_path)\n",
    "        cnt+=1\n",
    "        tarobject = tarfile.open(file_path)\n",
    "        tarobject.extractall(extract_path)\n",
    "        tarobject.close()\n",
    "        print('Extracted ', cnt, extract_path)\n",
    "        \n",
    "def extract_data():\n",
    "    unziped_spams = os.listdir(os.path.join(dataset_dir, 'mail_unziped/spam'))\n",
    "    \n",
    "    if len(unziped_spams) == 0:        \n",
    "        unzip_dir(spam_zip, spam_unzip)\n",
    "        unzip_dir(ham_zip, ham_unzip)\n",
    "    else:\n",
    "        print(unziped_spams)\n",
    "        print('Ziped files already extracted')\n",
    "        pass       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files_in_dir(path):\n",
    "    fullpaths  = []\n",
    "    for folder, subfolder, files in os.walk(path):\n",
    "        for file in files:\n",
    "            fullpaths.append(os.path.join(folder, file))\n",
    "            # print(os.path.join(folder, file))\n",
    "    return fullpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def get_words_from_email(emailpaths):\n",
    "    all_words = []\n",
    "    cnt = 0;\n",
    "\n",
    "    # cnt += 1\n",
    "    # print(mail)\n",
    "    for mailpath in emailpaths:\n",
    "        raw_data = ''\n",
    "        try:\n",
    "            #print(mailpath[:1][0])\n",
    "            raw_data = open(mailpath[:1][0], 'r', encoding='ascii', errors='surrogateescape').read()\n",
    "            with open(mailpath[:1][0], 'r', encoding='ascii', errors='surrogateescape') as read:\n",
    "                for line in read:\n",
    "                    cleaned_line = html_cleaner(str(line))\n",
    "                    #print(cleaned_line)\n",
    "                    all_words += cleaned_line.split()\n",
    "        except UnicodeDecodeError as ex:\n",
    "            print(ex)\n",
    "            print(raw_data)\n",
    " \n",
    "    dictionary = Counter(all_words)    \n",
    "    # remove single charactes\n",
    "    lst_to_remove = [i for i in dictionary.keys()]\n",
    "    cnt = len(lst_to_remove)\n",
    "    print(cnt)\n",
    "    # print(all_words)\n",
    "    for i in range(cnt):\n",
    "        item = lst_to_remove[i]\n",
    "        if item.isalpha() == False:\n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    print('finished')\n",
    "    words = [item.lower() for item in dictionary.keys()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def split_train_test_data(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    train = [i for i in data.iloc[train_indices]]\n",
    "    test = [i for i in data.iloc[test_indices]]\n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produce vectorized representation of each email.\n",
    "def get_features(files, vectorizer):\n",
    "    all_word_vec_shape = vectorizer.transform(['of the id and']).shape\n",
    "    labels = []\n",
    "    print(len(files))\n",
    "    train_labels = np.zeros(len(files))\n",
    "    vectorized_email = np.zeros((len(files), all_word_vec_shape[1]))\n",
    "                            \n",
    "    #vectorized_data  = np.zeros((len(files), all_word_vec_shape[1]))\n",
    "    vectorized_email\n",
    "    cnt = 0\n",
    "    for email in files:\n",
    "        # print(vectorizer.transform(email[:1]).toarray())\n",
    "        vectorized_email += vectorizer.transform(email[:1]).toarray()\n",
    "        #vectorized_data[cnt] = vectorizer.transform(email[:1]).toarray()\n",
    "        labels += email[1:]\n",
    "        # print(email[1:][0])\n",
    "        train_labels[cnt] = email[1:][0] \n",
    "        vectorized_email\n",
    "        cnt += 1\n",
    "    return vectorized_email, labels, train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam_2', 'spam']\n",
      "Ziped files already extracted\n",
      "2464 7770\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract compressed files \n",
    "extract_data()\n",
    "\n",
    "ham_paths = get_files_in_dir(ham_unzip)\n",
    "ham_emails = [[f, 0] for f in ham_paths]\n",
    "spam_emails = [[f, 1] for f in get_files_in_dir(spam_unzip)]\n",
    "\n",
    "print(len(spam_emails), len(ham_emails))\n",
    "\n",
    "# Combine spam and ham mails into one array\n",
    "emails = spam_emails + ham_emails\n",
    "len(emails)\n",
    "\n",
    "# Set aside test and train sets\n",
    "data = pd.Series(emails)\n",
    "train_set_files, test_set_files = split_train_test_data(data, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body_from_mail(emailpaths):\n",
    "    all_words = []\n",
    "    cnt = 0;\n",
    "\n",
    "    # cnt += 1\n",
    "    # print(mail)\n",
    "    mailpath = emailpaths\n",
    "    print(mailpath)\n",
    "    raw_data = ''\n",
    "    past_header, lines = False, []\n",
    "    try:\n",
    "    #print(mailpath[:1][0])\n",
    "    # raw_data = open(mailpath[:1][0], 'r', encoding='ascii', errors='surrogateescape').read()\n",
    "    # print(raw_data)\n",
    "    \n",
    "        with open(mailpath[:1][0], 'r', encoding='ascii', errors='surrogateescape') as read:\n",
    "            for line in read:\n",
    "                if past_header:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    past_header = True\n",
    "                #print(cleaned_line)\n",
    "    except UnicodeDecodeError as ex:\n",
    "        print(ex)\n",
    "        print(raw_data)\n",
    "    return lines\n",
    "\n",
    "#     dictionary = Counter(all_words)    \n",
    "#     # remove single charactes\n",
    "#     lst_to_remove = [i for i in dictionary.keys()]\n",
    "#     cnt = len(lst_to_remove)\n",
    "#     print(cnt)\n",
    "#     # print(all_words)\n",
    "#     for i in range(cnt):\n",
    "#         item = lst_to_remove[i]\n",
    "#         if item.isalpha() == False:\n",
    "#             del dictionary[item]\n",
    "#         elif len(item) == 1:\n",
    "#             del dictionary[item]\n",
    "#     print('finished')\n",
    "#     words = [item.lower() for item in dictionary.keys()]\n",
    "#    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/datadrive/PythonDev/datasets/Spam/mail_unziped/ham/easy_ham/00109.bcb73e4561798e05f2299471ab0be1bb', 0]\n"
     ]
    }
   ],
   "source": [
    "datas = get_body_from_mail(train_set_files[2])\n",
    "\n",
    "#words = get_words_from_email(train_set_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seems fetchmail has a -a switch to get it all.\\n',\n",
       " '\\n',\n",
       " 'Just need to install fetchmail now :)\\n',\n",
       " '\\n',\n",
       " 'Glen\\n',\n",
       " '\\n',\n",
       " 'On Mon, 2002-10-07 at 10:17, Stephane Dudzinski wrote:\\n',\n",
       " '> Funny enough, that also happened to a Friend of mine who uses both the\\n',\n",
       " '> web interface and a pop client. Last time i tried to send a picture\\n',\n",
       " '> which was around 100k, it got denied saying that quota was exceeded.\\n',\n",
       " '> When he looked at his account on the web, it mentionned 5 MB free, so i\\n',\n",
       " \"> have no idea what they're playing at ...\\n\",\n",
       " '> \\n',\n",
       " \"> Doesn't really help but just wanted to confirm the problem. \\n\",\n",
       " '> \\n',\n",
       " '> Steph\\n',\n",
       " '> \\n',\n",
       " '> On Mon, 2002-10-07 at 10:10, Glen Gray wrote:\\n',\n",
       " '> > Is there a way to get my read email downloaded off webmail.eircom.net.\\n',\n",
       " '> > \\n',\n",
       " \"> > I've been reading the emails using the web based interface. But I've\\n\",\n",
       " \"> > reached my quota limit. There doesn't seem to be any way to get the\\n\",\n",
       " '> > emails off the server. I can connect to the account using POP, but that\\n',\n",
       " \"> > only retrieves unread emails. There's also no way to mark emails as\\n\",\n",
       " '> > unread from the html interface.\\n',\n",
       " '> > \\n',\n",
       " '> > Is there a way I can use fetchmail perhaps to get it to pull down all\\n',\n",
       " '> > the emails and remove them off the server.\\n',\n",
       " '> > \\n',\n",
       " \"> > It's been years since I've used fetchmail, I don't recall be able to do\\n\",\n",
       " '> > this.\\n',\n",
       " '> > \\n',\n",
       " \"> > Any other suggestions welcome. There's a few hundred email so I don't\\n\",\n",
       " '> > fancy going through each one forwarding it to another account.\\n',\n",
       " '> > \\n',\n",
       " '> > Glen\\n',\n",
       " '> > \\n',\n",
       " '> > \\n',\n",
       " '> > \\n',\n",
       " '> > \\n',\n",
       " '> > -- \\n',\n",
       " \"> > Irish Linux Users' Group: ilug@linux.ie\\n\",\n",
       " '> > http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\n',\n",
       " '> > List maintainer: listmaster@linux.ie\\n',\n",
       " '> -- \\n',\n",
       " '> ______________________________________________\\n',\n",
       " '> Stephane Dudzinski       Systems Administrator\\n',\n",
       " '> NewWorldIQ            \\t     t: +353 1 4334357\\n',\n",
       " '> www.newworldiq.com           f: +353 1 4334301\\n',\n",
       " '> \\n',\n",
       " '> -- \\n',\n",
       " \"> Irish Linux Users' Group: ilug@linux.ie\\n\",\n",
       " '> http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\n',\n",
       " '> List maintainer: listmaster@linux.ie\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '-- \\n',\n",
       " \"Irish Linux Users' Group: ilug@linux.ie\\n\",\n",
       " 'http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\n',\n",
       " 'List maintainer: listmaster@linux.ie\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract words for feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219185\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', tokenizer=None, preprocessor=None, stop_words=None)\n",
    "\n",
    "# Get all words from emails\n",
    "words = get_words_from_email(train_set_files)\n",
    "\n",
    "reduced_words =[]\n",
    "for word in words:\n",
    "    if len(word) > 3 and len(word) <= 18:\n",
    "        reduced_words.append(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "fitted_words = vectorizer.fit_transform(reduced_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41479x32153 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41479 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aachen',\n",
       " 'aalib',\n",
       " 'aaliyah',\n",
       " 'aall',\n",
       " 'aanfh',\n",
       " 'aaron',\n",
       " 'aaronsw',\n",
       " 'aarp',\n",
       " 'aavid',\n",
       " 'aavishkar',\n",
       " 'aaxine',\n",
       " 'abacha',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abastecimientos',\n",
       " 'abatement',\n",
       " 'abbey',\n",
       " 'abbreviated',\n",
       " 'abbreviation',\n",
       " 'abdominal',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abel',\n",
       " 'abelard',\n",
       " 'aber',\n",
       " 'aberdeenshire',\n",
       " 'aberration',\n",
       " 'abetted',\n",
       " 'abetting',\n",
       " 'abide',\n",
       " 'abidjan',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abilitys',\n",
       " 'abiltiy',\n",
       " 'abilty',\n",
       " 'abit',\n",
       " 'abiword',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'ablility',\n",
       " 'ably',\n",
       " 'abnegate',\n",
       " 'abnegateall',\n",
       " 'abner',\n",
       " 'abnormal',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'aboli',\n",
       " 'abolins',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolition',\n",
       " 'abolute',\n",
       " 'abonnement',\n",
       " 'abonnements',\n",
       " 'aboriginal',\n",
       " 'aborigines',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'abortive',\n",
       " 'abounds',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abovementioned',\n",
       " 'abovetelefax',\n",
       " 'abraham',\n",
       " 'abreast',\n",
       " 'abreau',\n",
       " 'abridging',\n",
       " 'abroad',\n",
       " 'abruptly',\n",
       " 'absconded',\n",
       " 'absence',\n",
       " 'absense',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutes',\n",
       " 'absolutly',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorber',\n",
       " 'absorbers',\n",
       " 'absorbing',\n",
       " 'absorption',\n",
       " 'absquatulate',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstraction',\n",
       " 'abstractions',\n",
       " 'absultely',\n",
       " 'absurd',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'abubakar',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abys',\n",
       " 'abyss',\n",
       " 'abyssinian',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academical',\n",
       " 'academics',\n",
       " 'academy',\n",
       " 'acadians',\n",
       " 'acccount',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accelleration',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'acces',\n",
       " 'acceso',\n",
       " 'access',\n",
       " 'accessdetailed',\n",
       " 'accessed',\n",
       " 'accesses',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accessorized',\n",
       " 'accessory',\n",
       " 'accessto',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaimed',\n",
       " 'acclamation',\n",
       " 'acclimatise',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodation',\n",
       " 'accommodationist',\n",
       " 'accommodations',\n",
       " 'accomodations',\n",
       " 'accompagne',\n",
       " 'accompagnement',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accorded',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accords',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accredited',\n",
       " 'accross',\n",
       " 'accrue',\n",
       " 'accrued',\n",
       " 'acct',\n",
       " 'accumbuffer',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accumulation',\n",
       " 'accumulative',\n",
       " 'accumulator',\n",
       " 'accuracy',\n",
       " 'accuracyand',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'aced',\n",
       " 'acedl',\n",
       " 'acelet',\n",
       " 'acer',\n",
       " 'acerbic',\n",
       " 'acero',\n",
       " 'acessar',\n",
       " 'acesse',\n",
       " 'achats',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'achy',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acids',\n",
       " 'aciklamalari',\n",
       " 'acilan',\n",
       " 'ackno',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'ackup',\n",
       " 'aclamados',\n",
       " 'acls',\n",
       " 'acme',\n",
       " 'acne',\n",
       " 'acobley',\n",
       " 'aconite',\n",
       " 'acopia',\n",
       " 'acorn',\n",
       " 'acoustic',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquistion',\n",
       " 'acre',\n",
       " 'acres',\n",
       " 'acrobat',\n",
       " 'acronym',\n",
       " 'acroos',\n",
       " 'across',\n",
       " 'acrylamide',\n",
       " 'acrylic',\n",
       " 'actaully',\n",
       " 'acted',\n",
       " 'acterna',\n",
       " 'acteurs',\n",
       " 'actigis',\n",
       " 'actimates',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actioned',\n",
       " 'actionjim',\n",
       " 'actionnaire',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activating',\n",
       " 'activation',\n",
       " 'activator',\n",
       " 'active',\n",
       " 'activebuddy',\n",
       " 'actively',\n",
       " 'activement',\n",
       " 'activesync',\n",
       " 'activex',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activites',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actlab',\n",
       " 'acton',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuales',\n",
       " 'actually',\n",
       " 'actuallyreverses',\n",
       " 'actualy',\n",
       " 'actuators',\n",
       " 'acually',\n",
       " 'acuitive',\n",
       " 'acustomed',\n",
       " 'acute',\n",
       " 'acyclovir',\n",
       " 'adabas',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adamantly',\n",
       " 'adams',\n",
       " 'adamson',\n",
       " 'adapt',\n",
       " 'adaptations',\n",
       " 'adaptec',\n",
       " 'adapted',\n",
       " 'adaptedforuse',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adapting',\n",
       " 'adaptive',\n",
       " 'adapts',\n",
       " 'adare',\n",
       " 'adaware',\n",
       " 'adays',\n",
       " 'adbusters',\n",
       " 'added',\n",
       " 'addes',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'additive',\n",
       " 'addmodule',\n",
       " 'addprefsto',\n",
       " 'addreses',\n",
       " 'address',\n",
       " 'addressable',\n",
       " 'addressbook',\n",
       " 'addressbooks',\n",
       " 'addressed',\n",
       " 'addressee',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'addrs',\n",
       " 'adds',\n",
       " 'addversionno',\n",
       " 'adeel',\n",
       " 'adelaide',\n",
       " 'adelie',\n",
       " 'adelphia',\n",
       " 'adenophora',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adet',\n",
       " 'adewale',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adherence',\n",
       " 'adherents',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adhesion',\n",
       " 'adhesive',\n",
       " 'adhesives',\n",
       " 'adjacent',\n",
       " 'adjoining',\n",
       " 'adjourned',\n",
       " 'adjournment',\n",
       " 'adjournments',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjusts',\n",
       " 'adler',\n",
       " 'admin',\n",
       " 'admining',\n",
       " 'admininstration',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administrate',\n",
       " 'administrateur',\n",
       " 'administration',\n",
       " 'administrativa',\n",
       " 'administrative',\n",
       " 'administrativo',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'admiral',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admonish',\n",
       " 'admonished',\n",
       " 'adobe',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoptee',\n",
       " 'adopter',\n",
       " 'adopters',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adopts',\n",
       " 'adore',\n",
       " 'adpcm',\n",
       " 'adprogram',\n",
       " 'adrenal',\n",
       " 'adres',\n",
       " 'adresinde',\n",
       " 'adresinize',\n",
       " 'adreslerini',\n",
       " 'adress',\n",
       " 'adresse',\n",
       " 'adresser',\n",
       " 'adrian',\n",
       " 'adroitly',\n",
       " 'adservers',\n",
       " 'adsit',\n",
       " 'adsl',\n",
       " 'adult',\n",
       " 'adultclub',\n",
       " 'adultery',\n",
       " 'adults',\n",
       " 'adultwebmasters',\n",
       " 'advalvas',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advantagesm',\n",
       " 'advantech',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversaries',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advert',\n",
       " 'adverting',\n",
       " 'advertis',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advertisments',\n",
       " 'advertizing',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advicer',\n",
       " 'advices',\n",
       " 'advisability',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'adviseby',\n",
       " 'advised',\n",
       " 'advisement',\n",
       " 'adviser',\n",
       " 'advises',\n",
       " 'advisor',\n",
       " 'advisories',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'aeftr',\n",
       " 'aeopublishing',\n",
       " 'aerial',\n",
       " 'aerials',\n",
       " 'aernet',\n",
       " 'aerodynamical',\n",
       " 'aerodynamics',\n",
       " 'aeronautical',\n",
       " 'aerosol',\n",
       " 'aerospace',\n",
       " 'aesthetic',\n",
       " 'aesthetics',\n",
       " 'afaics',\n",
       " 'afaik',\n",
       " 'afair',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affectional',\n",
       " 'affective',\n",
       " 'affects',\n",
       " 'affidavit',\n",
       " 'affidavits',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affiliates',\n",
       " 'affiliation',\n",
       " 'affiliations',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmed',\n",
       " 'affix',\n",
       " 'affixed',\n",
       " 'affleck',\n",
       " 'afflicted',\n",
       " 'affliction',\n",
       " 'afflictions',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'affordably',\n",
       " 'afforded',\n",
       " 'affronts',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afield',\n",
       " 'afin',\n",
       " 'afirstcome',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afpe',\n",
       " 'afraid',\n",
       " 'afree',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africaspainsri',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'afterglow',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'aftersales',\n",
       " 'afterstep',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'agai',\n",
       " 'again',\n",
       " 'againn',\n",
       " 'against',\n",
       " 'againts',\n",
       " 'agat',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'ageist',\n",
       " 'ageless',\n",
       " 'agence',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggrandizement',\n",
       " 'aggregate',\n",
       " 'aggregated',\n",
       " 'aggregating',\n",
       " 'aggregation',\n",
       " 'aggregator',\n",
       " 'aggregators',\n",
       " 'aggression',\n",
       " 'aggressions',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressor',\n",
       " 'aggressors',\n",
       " 'aghast',\n",
       " 'agile',\n",
       " 'aging',\n",
       " 'aginst',\n",
       " 'agitated',\n",
       " 'agitating',\n",
       " 'agnostic',\n",
       " 'agnula',\n",
       " 'agonising',\n",
       " 'agonizing',\n",
       " 'agora',\n",
       " 'agosto',\n",
       " 'agraphic',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreemeent',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agregado',\n",
       " 'agressively',\n",
       " 'agribusiness',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'aground',\n",
       " 'agtel',\n",
       " 'agument',\n",
       " 'agus',\n",
       " 'ahead',\n",
       " 'aherne',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahmad',\n",
       " 'ahmadabad',\n",
       " 'ahmed',\n",
       " 'ahmet',\n",
       " 'ahold',\n",
       " 'ahole',\n",
       " 'ahotsexycouple',\n",
       " 'aicheme',\n",
       " 'aicn',\n",
       " 'aidan',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aider',\n",
       " 'aides',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aidsphobic',\n",
       " 'aihf',\n",
       " 'aileen',\n",
       " 'ailleurs',\n",
       " 'ailments',\n",
       " 'ails',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aiml',\n",
       " 'aims',\n",
       " 'aine',\n",
       " 'ained',\n",
       " 'aining',\n",
       " 'ainsi',\n",
       " 'aint',\n",
       " 'airbase',\n",
       " 'airborne',\n",
       " 'airbus',\n",
       " 'aircraft',\n",
       " 'aircrafts',\n",
       " 'aired',\n",
       " 'airfare',\n",
       " 'airfield',\n",
       " 'airfiltering',\n",
       " 'airflow',\n",
       " 'airing',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airliners',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airshow',\n",
       " 'airshows',\n",
       " 'airspace',\n",
       " 'airstrip',\n",
       " 'airwaves',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'airy',\n",
       " 'aishat',\n",
       " 'aishihik',\n",
       " 'aishling',\n",
       " 'aisle',\n",
       " 'ajami',\n",
       " 'ajaokuta',\n",
       " 'ajatellut',\n",
       " 'ajuda',\n",
       " 'akamai',\n",
       " 'akamorbus',\n",
       " 'akesson',\n",
       " 'akin',\n",
       " 'akitogo',\n",
       " 'akkabay',\n",
       " 'aknmq',\n",
       " 'aknowledging',\n",
       " 'akorty',\n",
       " 'aksine',\n",
       " 'alab',\n",
       " 'alabama',\n",
       " 'alabi',\n",
       " 'alacribus',\n",
       " 'aladin',\n",
       " 'alain',\n",
       " 'alamos',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarmes',\n",
       " 'alarming',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alastair',\n",
       " 'alavanca',\n",
       " 'albacore',\n",
       " 'albania',\n",
       " 'albans',\n",
       " 'albedo',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertans',\n",
       " 'albiet',\n",
       " 'albino',\n",
       " 'albion',\n",
       " 'albizzia',\n",
       " 'albrecht',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcances',\n",
       " 'alcanet',\n",
       " 'alcatel',\n",
       " 'alchemy',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcoholics',\n",
       " 'alden',\n",
       " 'aldiginizda',\n",
       " 'aldridge',\n",
       " 'aleikum',\n",
       " 'aler',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alerting',\n",
       " 'alerts',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandre',\n",
       " 'alexandria',\n",
       " 'alexis',\n",
       " 'alfio',\n",
       " 'alfred',\n",
       " 'algebra',\n",
       " 'algeria',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'algos',\n",
       " 'alhaji',\n",
       " 'alias',\n",
       " 'aliases',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'aligator',\n",
       " 'alight',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alimony',\n",
       " 'alip',\n",
       " 'alisma',\n",
       " 'alison',\n",
       " 'alists',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'alkaloid',\n",
       " 'alkaloids',\n",
       " 'allan',\n",
       " 'allay',\n",
       " 'allchin',\n",
       " 'alleasilybe',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegience',\n",
       " 'alleging',\n",
       " 'allegro',\n",
       " 'allemands',\n",
       " 'allen',\n",
       " 'allendale',\n",
       " 'aller',\n",
       " 'allergies',\n",
       " 'allesklar',\n",
       " 'alleviate',\n",
       " 'alleviated',\n",
       " 'alley',\n",
       " 'alleycat',\n",
       " 'alleys',\n",
       " 'alleyways',\n",
       " 'allez',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allie',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'allman',\n",
       " 'allmerica',\n",
       " 'allnum',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allocating',\n",
       " 'allocation',\n",
       " 'allodial',\n",
       " 'allodium',\n",
       " 'allof',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowedduppkgs',\n",
       " 'allowing',\n",
       " 'allowrootuser',\n",
       " 'allows',\n",
       " 'alloy',\n",
       " 'allthe',\n",
       " 'alltheweb',\n",
       " 'allude',\n",
       " 'alluded',\n",
       " 'allvalid',\n",
       " 'allways',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almak',\n",
       " 'almighty',\n",
       " 'almost',\n",
       " 'alms',\n",
       " 'alng',\n",
       " 'aloft',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alook',\n",
       " 'alookat',\n",
       " 'alors',\n",
       " 'alot',\n",
       " 'alpen',\n",
       " 'alper',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alphabetic',\n",
       " 'alphabetical',\n",
       " 'alphabetically',\n",
       " 'alphabets',\n",
       " 'alpharetta',\n",
       " 'alphie',\n",
       " 'alphyra',\n",
       " 'alps',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alsa',\n",
       " 'alsamixer',\n",
       " 'alsaplaer',\n",
       " 'alsaplayer',\n",
       " 'alsasound',\n",
       " 'also',\n",
       " 'alsoofferyou',\n",
       " 'alspach',\n",
       " 'alston',\n",
       " 'alta',\n",
       " 'altaexchange',\n",
       " 'altamente',\n",
       " 'altavista',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'alternance',\n",
       " 'alternate',\n",
       " 'alternated',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternativas',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'alternativetry',\n",
       " 'although',\n",
       " 'altimetery',\n",
       " 'altinda',\n",
       " 'altitude',\n",
       " 'altitudes',\n",
       " 'altman',\n",
       " 'alto',\n",
       " 'altogether',\n",
       " 'alton',\n",
       " 'altough',\n",
       " 'altruism',\n",
       " 'altus',\n",
       " 'aluko',\n",
       " 'aluminio',\n",
       " 'aluminum',\n",
       " 'alumni',\n",
       " 'alumnus',\n",
       " 'alva',\n",
       " 'alvie',\n",
       " 'always',\n",
       " 'amalgamated',\n",
       " 'amalgamation',\n",
       " 'amanda',\n",
       " 'amass',\n",
       " 'amassed',\n",
       " 'amassing',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurs',\n",
       " 'amavis',\n",
       " 'amavisd',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amazonian',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambient',\n",
       " 'ambiente',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambivalence',\n",
       " 'ambivalent',\n",
       " 'ambrose',\n",
       " 'ambrosini',\n",
       " 'ambulance',\n",
       " 'ambulances',\n",
       " 'amdended',\n",
       " 'amend',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amendment',\n",
       " 'amendments',\n",
       " 'amenities',\n",
       " 'america',\n",
       " 'americal',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'americorps',\n",
       " 'americorpsvista',\n",
       " 'amerus',\n",
       " 'amex',\n",
       " 'amherst',\n",
       " 'amiable',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amiga',\n",
       " 'amigaos',\n",
       " 'amino',\n",
       " 'amis',\n",
       " 'amit',\n",
       " 'amithisornot',\n",
       " 'amithlon',\n",
       " 'amla',\n",
       " 'amlcd',\n",
       " 'ammend',\n",
       " 'ammendement',\n",
       " 'ammo',\n",
       " 'ammunition',\n",
       " 'ammunitions',\n",
       " 'amnesiac',\n",
       " 'amnesty',\n",
       " 'amnis',\n",
       " 'amnm',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50461003,  0.50461003,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = vectorizer.transform(['aalib aachen allows alloy']).toarray()\n",
    "xx = vectorizer.transform(['of the id and'])\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_word_vec_shape = vectorizer.transform(['of the id and'])\n",
    "\n",
    "all_word_vec_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, x_labels = get_features(train_set_files, vectorizer)\n",
    "y_train, y_test, y_labels = get_features(test_set_files, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "model = SVC()\n",
    "model.fit(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_labels)):\n",
    "    if result[i] == 1:\n",
    "        print(result[i], y_labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
